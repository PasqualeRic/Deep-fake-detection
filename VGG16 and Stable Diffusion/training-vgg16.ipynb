{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1462296,"sourceType":"datasetVersion","datasetId":857191},{"sourceId":9574814,"sourceType":"datasetVersion","datasetId":5836852},{"sourceId":9581197,"sourceType":"datasetVersion","datasetId":5842193},{"sourceId":9581298,"sourceType":"datasetVersion","datasetId":5842268}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install diffusers","metadata":{"execution":{"iopub.status.busy":"2024-10-08T22:02:58.497054Z","iopub.execute_input":"2024-10-08T22:02:58.497510Z","iopub.status.idle":"2024-10-08T22:03:14.079704Z","shell.execute_reply.started":"2024-10-08T22:02:58.497472Z","shell.execute_reply":"2024-10-08T22:03:14.078544Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting diffusers\n  Downloading diffusers-0.30.3-py3-none-any.whl.metadata (18 kB)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.10/site-packages (from diffusers) (7.0.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from diffusers) (3.15.1)\nRequirement already satisfied: huggingface-hub>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from diffusers) (0.25.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from diffusers) (1.26.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from diffusers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from diffusers) (2.32.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from diffusers) (0.4.5)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from diffusers) (10.3.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.2->diffusers) (2024.6.1)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.2->diffusers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.2->diffusers) (6.0.2)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.2->diffusers) (4.66.4)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.2->diffusers) (4.12.2)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata->diffusers) (3.19.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->diffusers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->diffusers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->diffusers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->diffusers) (2024.8.30)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.23.2->diffusers) (3.1.2)\nDownloading diffusers-0.30.3-py3-none-any.whl (2.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hInstalling collected packages: diffusers\nSuccessfully installed diffusers-0.30.3\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install pycocotools","metadata":{"execution":{"iopub.status.busy":"2024-10-08T22:03:15.745200Z","iopub.execute_input":"2024-10-08T22:03:15.745639Z","iopub.status.idle":"2024-10-08T22:03:28.472654Z","shell.execute_reply.started":"2024-10-08T22:03:15.745594Z","shell.execute_reply":"2024-10-08T22:03:28.471433Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting pycocotools\n  Downloading pycocotools-2.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\nRequirement already satisfied: matplotlib>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from pycocotools) (3.7.5)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from pycocotools) (1.26.4)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (10.3.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (2.9.0.post0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools) (1.16.0)\nDownloading pycocotools-2.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (427 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m427.8/427.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pycocotools\nSuccessfully installed pycocotools-2.0.8\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom diffusers import DiffusionPipeline\nfrom torchvision import models, transforms\nfrom PIL import Image\nimport os\nfrom pycocotools.coco import COCO\nimport numpy as np\nfrom sklearn.svm import SVC\nimport joblib\nimport concurrent.futures\nfrom accelerate import Accelerator","metadata":{"execution":{"iopub.status.busy":"2024-10-08T22:03:28.474765Z","iopub.execute_input":"2024-10-08T22:03:28.475181Z","iopub.status.idle":"2024-10-08T22:03:51.688146Z","shell.execute_reply.started":"2024-10-08T22:03:28.475131Z","shell.execute_reply":"2024-10-08T22:03:51.687034Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5938e162dc7d4d538ee31ef3ab5f979b"}},"metadata":{}}]},{"cell_type":"code","source":"# The train2017 and instances_train2017_subset are subsets of COCO's dataset, they contain only 2000 images\ncoco_root = '/kaggle/input/coco-2017-dataset/coco2017/train2017'\ncoco_annotation_file = '/kaggle/input/coco-2017-dataset/coco2017/annotations/instances_train2017.json'\ncoco = COCO(coco_annotation_file)\ngan_root = '/kaggle/input/gan-2000-images-64x64' \n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-08T22:09:29.091150Z","iopub.execute_input":"2024-10-08T22:09:29.091575Z","iopub.status.idle":"2024-10-08T22:09:56.281208Z","shell.execute_reply.started":"2024-10-08T22:09:29.091535Z","shell.execute_reply":"2024-10-08T22:09:56.280218Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"loading annotations into memory...\nDone (t=26.00s)\ncreating index...\nindex created!\n","output_type":"stream"}]},{"cell_type":"code","source":"# Check if I have a GPU available \ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\ndtype = torch.float16 if device == \"cuda\" else torch.float32\n\n# Inizializza Accelerator per la gestione delle GPU\naccelerator = Accelerator()","metadata":{"execution":{"iopub.status.busy":"2024-10-08T22:03:54.305215Z","iopub.execute_input":"2024-10-08T22:03:54.305953Z","iopub.status.idle":"2024-10-08T22:03:54.417560Z","shell.execute_reply.started":"2024-10-08T22:03:54.305912Z","shell.execute_reply":"2024-10-08T22:03:54.416676Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Funzione per estrarre caratteristiche con VGG\ndef extract_vgg_features(image, model):\n    preprocess = transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    ])\n    input_tensor = preprocess(image).unsqueeze(0).to(accelerator.device)  # add the dimension batch and transfer to the GPU\n    with torch.no_grad():\n        features = model(input_tensor)\n    return features.flatten().cpu().numpy()\n# Load a VGG16 pre-trained model and remove the last layer\nvgg16 = models.vgg16(pretrained=True)\nvgg16.classifier = vgg16.classifier[:-1]  # remove the last layer\nvgg16.eval().to(accelerator.device)  # put in eval modality and transfer to the GPU","metadata":{"execution":{"iopub.status.busy":"2024-10-08T22:03:56.492810Z","iopub.execute_input":"2024-10-08T22:03:56.493224Z","iopub.status.idle":"2024-10-08T22:04:01.343700Z","shell.execute_reply.started":"2024-10-08T22:03:56.493186Z","shell.execute_reply":"2024-10-08T22:04:01.342549Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n100%|██████████| 528M/528M [00:02<00:00, 209MB/s]  \n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"VGG(\n  (features): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU(inplace=True)\n    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (3): ReLU(inplace=True)\n    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (6): ReLU(inplace=True)\n    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (8): ReLU(inplace=True)\n    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (11): ReLU(inplace=True)\n    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (13): ReLU(inplace=True)\n    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (15): ReLU(inplace=True)\n    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (18): ReLU(inplace=True)\n    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (20): ReLU(inplace=True)\n    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (22): ReLU(inplace=True)\n    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (25): ReLU(inplace=True)\n    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (27): ReLU(inplace=True)\n    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (29): ReLU(inplace=True)\n    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n  (classifier): Sequential(\n    (0): Linear(in_features=25088, out_features=4096, bias=True)\n    (1): ReLU(inplace=True)\n    (2): Dropout(p=0.5, inplace=False)\n    (3): Linear(in_features=4096, out_features=4096, bias=True)\n    (4): ReLU(inplace=True)\n    (5): Dropout(p=0.5, inplace=False)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"def save_image_256(image, save_dir, img_id):\n    os.makedirs(save_dir, exist_ok=True)  # Crea la cartella se non esiste\n    save_path = os.path.join(save_dir, f\"image_256x256{img_id}.jpg\")\n    image.save(save_path, format=\"JPEG\")\n    print(f\"Immagine salvata in: {save_path}\")\ndef save_image_64(image, save_dir, img_id):\n    os.makedirs(save_dir, exist_ok=True)  # Crea la cartella se non esiste\n    save_path = os.path.join(save_dir, f\"image_64x64{img_id}.jpg\")\n    image.save(save_path, format=\"JPEG\")\n    print(f\"Immagine salvata in: {save_path}\")\ndef save_image_fake(image, save_dir, img_id):\n    os.makedirs(save_dir, exist_ok=True)  # Crea la cartella se non esiste\n    save_path = os.path.join(save_dir, f\"fake_image_{img_id}.jpg\")\n    image.save(save_path, format=\"JPEG\")\n    print(f\"Immagine salvata in: {save_path}\")\n# Funzione per salvare le immagini reali\ndef save_image_real(image, save_dir, img_id):\n    os.makedirs(save_dir, exist_ok=True)  # Crea la cartella se non esiste\n    save_path = os.path.join(save_dir, f\"real_image_{img_id}.jpg\")\n    image.save(save_path, format=\"JPEG\")\n    print(f\"Immagine salvata in: {save_path}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-08T22:04:03.119100Z","iopub.execute_input":"2024-10-08T22:04:03.119460Z","iopub.status.idle":"2024-10-08T22:04:03.130820Z","shell.execute_reply.started":"2024-10-08T22:04:03.119426Z","shell.execute_reply":"2024-10-08T22:04:03.129730Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Carica il modello di diffusione\npipeline = DiffusionPipeline.from_pretrained(\"stabilityai/stable-diffusion-2-1\", torch_dtype=dtype)\npipeline.to(accelerator.device)\n\n# Funzione per generare immagini\ndef generate_image(prompt):\n    image = pipeline(prompt, num_inference_steps=8).images[0]\n    return image.convert(\"RGB\")\n\n\n# Directory di salvataggio\nreal_dir = \"/kaggle/working/real_images\"\nfake_dir = \"/kaggle/working/fake_images\"\nclassifier = SVC(kernel='linear')  # Usa tutte le CPU disponibili\nfeatures_list = []\nlabels = []\nlast_step = 0\n\n# Estrai immagini da COCO\nimage_ids = coco.getImgIds()\nsample_ids = image_ids[last_step:]\n\nstep = 0\n\n# Generazione immagini e raccolta caratteristiche tqdm\nfor img_id in sample_ids:\n    img_data = coco.imgs[img_id]\n    img_path = os.path.join(coco_root, img_data['file_name'])\n    if step >= 2000:  # Limita a 2000 immagini\n        break\n\n    try:\n        # Immagine reale\n        image_real = Image.open(img_path).convert(\"RGB\")\n        real_features = extract_vgg_features(image_real, vgg16)\n        features_list.append(real_features)\n        labels.append(1)  # etichetta per le immagini reali\n        save_image_real(image_real, real_dir, img_id)\n\n        # Ottieni categorie per generare immagini fake\n        ann_ids = coco.getAnnIds(imgIds=[img_id], iscrowd=False)\n        anns = coco.loadAnns(ann_ids)\n        categories = [coco.cats[ann['category_id']]['name'] for ann in anns]\n        prompt = \", \".join(categories)\n\n        # Generazione immagini in parallelo\n        with concurrent.futures.ThreadPoolExecutor() as executor:\n            future_image = executor.submit(generate_image, prompt)\n            image_fake = future_image.result()  # Aspetta il risultato\n            save_image_fake(image_fake, fake_dir, img_id)\n\n        fake_features = extract_vgg_features(image_fake, vgg16)\n        features_list.append(fake_features)\n        labels.append(0)  # etichetta per le immagini fake\n\n        step += 1\n\n    except Exception as e:\n        print(f\"Errore nell'elaborazione dell'immagine ID {img_id}: {e}\")\n\nstep = 0\n# Elaborazione delle immagini GAN\ngan_images = os.listdir(gan_root)\nfor gan_img_name in gan_images:\n    img_path = os.path.join(gan_root, gan_img_name)\n    try:\n        # Immagine GAN\n        gan_image = Image.open(img_path).convert(\"RGB\")\n        gan_features = extract_vgg_features(gan_image, vgg16)\n        features_list.append(gan_features)\n        labels.append(0)  # etichetta per le immagini GAN\n        print(step)\n        step += 1\n\n    except Exception as e:\n        print(f\"Errore nell'elaborazione dell'immagine ID {img_id}: {e}\")\n\n# Addestra il classificatore SVM\nclassifier.fit(features_list, labels)\n\n# Salva il modello finale\njoblib.dump(classifier, 'svm_classifier.pkl')\nprint(\"Modello SVM salvato come 'svm_classifier.pkl'\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-08T22:10:07.015766Z","iopub.execute_input":"2024-10-08T22:10:07.016162Z","iopub.status.idle":"2024-10-08T22:10:30.763546Z","shell.execute_reply.started":"2024-10-08T22:10:07.016123Z","shell.execute_reply":"2024-10-08T22:10:30.762126Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2b621695b7a4b059b82cfb4b3cb6709"}},"metadata":{}},{"name":"stdout","text":"Immagine salvata in: /kaggle/working/real_images/real_image_391895.jpg\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/8 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"74f0a55982de4007a0ae75421d6795e6"}},"metadata":{}},{"name":"stdout","text":"Immagine salvata in: /kaggle/working/fake_images/fake_image_391895.jpg\nImmagine salvata in: /kaggle/working/real_images/real_image_522418.jpg\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/8 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"437b5252062b4e648bc53d79f890d4a3"}},"metadata":{}},{"name":"stdout","text":"Immagine salvata in: /kaggle/working/fake_images/fake_image_522418.jpg\nImmagine salvata in: /kaggle/working/real_images/real_image_184613.jpg\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/8 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ea50bb4dd804584ae35d6b59edd5fc7"}},"metadata":{}},{"name":"stdout","text":"Immagine salvata in: /kaggle/working/fake_images/fake_image_184613.jpg\nImmagine salvata in: /kaggle/working/real_images/real_image_318219.jpg\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/8 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1b843056ff74e0f85abbfd3536cd2ec"}},"metadata":{}},{"name":"stdout","text":"Immagine salvata in: /kaggle/working/fake_images/fake_image_318219.jpg\nImmagine salvata in: /kaggle/working/real_images/real_image_554625.jpg\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/8 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c8de4f95a52465daa904087ccf01cd9"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[10], line 49\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mThreadPoolExecutor() \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m     48\u001b[0m     future_image \u001b[38;5;241m=\u001b[39m executor\u001b[38;5;241m.\u001b[39msubmit(generate_image, prompt)\n\u001b[0;32m---> 49\u001b[0m     image_fake \u001b[38;5;241m=\u001b[39m \u001b[43mfuture_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Aspetta il risultato\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     save_image_fake(image_fake, fake_dir, img_id)\n\u001b[1;32m     52\u001b[0m fake_features \u001b[38;5;241m=\u001b[39m extract_vgg_features(image_fake, vgg16)\n","File \u001b[0;32m/opt/conda/lib/python3.10/concurrent/futures/_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 453\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n","File \u001b[0;32m/opt/conda/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"# The train2017 and instances_train2017_subset are subsets of COCO's dataset, they contain only 2000 images\ncoco_root = '/kaggle/input/coco-subset'\ngan_root = '/kaggle/input/gan-2000-images-64x64' \nstable_root = '/kaggle/input/stable-diffusion'\n\n# Funzione per upsampling a 256x256 se la dimensione è inferiore a 256x256\ndef upsample_to_256(image):\n    if image.size[0] < 256 or image.size[1] < 256:\n        return image.resize((256, 256), Image.BICUBIC)\n    return image\n\n# Funzione per downsampling a 256x256 se la dimensione è superiore a 256x256\ndef downsample_to_256(image):\n    if image.size[0] > 256 or image.size[1] > 256:\n        return image.resize((256, 256), Image.LANCZOS)\n    return image\n# Funzione per downsampling a 64x64 se la dimensione è superiore a 64x64\ndef downsample_to_64(image):\n    if image.size[0] > 64 or image.size[1] > 64:\n        return image.resize((64, 64), Image.LANCZOS)\n    return image\n\n#directory salvataggio immagini\noriginal_dir = \"/kaggle/working/original\"\ngan_dir = \"/kaggle/working/gan\"\nstable_dir = \"/kaggle/working/stable\"\n\nclassifier_256 = SVC(kernel='linear')  # Usa tutte le CPU disponibili\nclassifier_64 = SVC(kernel='linear')\n\nfeatures_list_256 = []\nfeatures_list_64 = []\nlabels_256 = []\nlabels_64 = []\n\n# Estrai immagini da COCO\ncoco_images = os.listdir(coco_root)\n\n#estrai immagini da gan\ngan_images = os.listdir(gan_root)\n\n#estrai immagini da stable\nstable_images = os.listdir(stable_root)\n\nstep = 0\noriginal = True\ngan = True\nstable = True\n\n#Append coco's image\nprint(\"sei in coco\")\nfor coco_img_name in coco_images:\n    img_path = os.path.join(coco_root, coco_img_name)\n    try:\n        # Immagine reale\n        img = Image.open(img_path).convert(\"RGB\")\n        image_real_256 = downsample_to_256(img)\n        image_real_64 = downsample_to_64(img)\n        if(original == True):\n            save_image_real(img, original_dir, coco_img_name)\n            save_image_256(image_real_256, original_dir, coco_img_name)\n            save_image_64(image_real_64, original_dir, coco_img_name)\n            original = False\n            \n        real_features_256 = extract_vgg_features(image_real_256, vgg16)\n        real_features_64 = extract_vgg_features(image_real_64, vgg16)\n        \n        features_list_256.append(real_features_256)\n        features_list_64.append(real_features_64)\n        \n        labels_256.append(1)  # etichetta per le immagini reali\n        labels_64.append(1)\n        step += 1\n\n    except Exception as e:\n        print(f\"Errore nell'elaborazione dell'immagine ID {coco_img_name}: {e}\")\n        \n#Append stable's image\nstep = 0\nprint(\"sei in stable\")\nfor stable_img_name in stable_images:\n    img_path = os.path.join(stable_root, stable_img_name)\n\n    try:\n        # Immagine da Stable Diffusion\n        img = Image.open(img_path).convert(\"RGB\")\n        image_stable_256 = downsample_to_256(img)\n        image_stable_64 = downsample_to_64(img)\n        if(stable == True):\n            save_image_fake(img, stable_dir, stable_img_name)\n            save_image_256(image_stable_256, stable_dir, stable_img_name)\n            save_image_64(image_stable_64, stable_dir, stable_img_name)\n            stable = False\n            \n        stable_features_256 = extract_vgg_features(image_stable_256, vgg16)\n        stable_features_64 = extract_vgg_features(image_stable_64, vgg16)\n        \n        features_list_256.append(stable_features_256)\n        features_list_64.append(stable_features_64)\n        \n        labels_256.append(0)  # etichetta per le immagini reali\n        labels_64.append(0)\n        step += 1\n    except Exception as e:\n        print(f\"Errore nell'elaborazione dell'immagine Stable {stable_img_name}: {e}\")\n\n\n# Elaborazione delle immagini GAN\nstep = 0\nprint(\"sei in gan\")\nfor gan_img_name in gan_images:\n    img_path = os.path.join(gan_root, gan_img_name)\n\n    try:\n        # Immagine da Stable Diffusion\n        img = Image.open(img_path).convert(\"RGB\")\n        image_gan_256 = upsample_to_256(img)\n        if(gan == True):\n            save_image_fake(img, gan_dir, gan_img_name)\n            save_image_256(image_gan_256, gan_dir, gan_img_name)\n            save_image_64(img, gan_dir, gan_img_name)\n            gan = False\n        gan_features_256 = extract_vgg_features(image_gan_256, vgg16)\n        gan_features_64 = extract_vgg_features(img, vgg16)\n        \n        features_list_256.append(gan_features_256)\n        features_list_64.append(gan_features_64)\n        \n        labels_256.append(0)  # etichetta per le immagini reali\n        labels_64.append(0)\n        step += 1\n    except Exception as e:\n        print(f\"Errore nell'elaborazione dell'immagine Gan {gan_img_name}: {e}\")\n\n\n# Addestra il classificatore SVM\nclassifier_256.fit(features_list_256, labels_256)\nclassifier_64.fit(features_list_256, labels_64)\n\n# Salva il modello finale\njoblib.dump(classifier_256, 'svm_classifier_256.pkl')\nprint(\"Modello SVM salvato come 'svm_classifier_256.pkl'\")\njoblib.dump(classifier_64, 'svm_classifier_64.pkl')","metadata":{"execution":{"iopub.status.busy":"2024-10-08T22:04:12.237985Z","iopub.execute_input":"2024-10-08T22:04:12.238867Z","iopub.status.idle":"2024-10-08T22:08:45.165697Z","shell.execute_reply.started":"2024-10-08T22:04:12.238828Z","shell.execute_reply":"2024-10-08T22:08:45.164735Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"sei in coco\nImmagine salvata in: /kaggle/working/original/real_image_real_image_248242.jpg.jpg\nImmagine salvata in: /kaggle/working/original/image_256x256real_image_248242.jpg.jpg\nImmagine salvata in: /kaggle/working/original/image_64x64real_image_248242.jpg.jpg\nsei in stable\nImmagine salvata in: /kaggle/working/stable/fake_image_fake_image_356406.jpg.jpg\nImmagine salvata in: /kaggle/working/stable/image_256x256fake_image_356406.jpg.jpg\nImmagine salvata in: /kaggle/working/stable/image_64x64fake_image_356406.jpg.jpg\nsei in gan\nImmagine salvata in: /kaggle/working/gan/fake_image_generated_image_1260.png.jpg\nImmagine salvata in: /kaggle/working/gan/image_256x256generated_image_1260.png.jpg\nImmagine salvata in: /kaggle/working/gan/image_64x64generated_image_1260.png.jpg\nModello SVM salvato come 'svm_classifier_256.pkl'\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"['svm_classifier_64.pkl']"},"metadata":{}}]},{"cell_type":"code","source":"import shutil\n\n# Specifica il percorso della cartella che vuoi comprimere\nfolder_to_zip = '/kaggle/working/stable'  # Sostituisci con il percorso della tua cartella\noutput_zip = '/kaggle/working/stable.zip'\n\n# Crea un file ZIP della cartella\nshutil.make_archive(folder_to_zip, 'zip', folder_to_zip)","metadata":{"execution":{"iopub.status.busy":"2024-10-08T21:51:06.741159Z","iopub.execute_input":"2024-10-08T21:51:06.741984Z","iopub.status.idle":"2024-10-08T21:51:06.754990Z","shell.execute_reply.started":"2024-10-08T21:51:06.741938Z","shell.execute_reply":"2024-10-08T21:51:06.754079Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/stable.zip'"},"metadata":{}}]}]}